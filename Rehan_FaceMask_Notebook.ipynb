{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask_Part2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef2SGvy3ZTBJ"
      },
      "source": [
        "############################################\n",
        "##########  Import Libraries  #############\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3BzlOt6bHDm"
      },
      "source": [
        "###################  Import Keras Related Functions  ############\n",
        "from tensorflow.keras.models import Sequential,load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import time"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AZmjpEWb1P9",
        "outputId": "97f463ef-96b3-4086-d9ce-f9a00718c3d5"
      },
      "source": [
        "########################################################\n",
        "###########  Mount Google Derive ######################\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xyr-NSW_YcFi"
      },
      "source": [
        "# Preprocessing Step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yhNjqXOtcnC"
      },
      "source": [
        "########################################################3\n",
        "#######  Some Variables for Data   #####################\n",
        "trainingDataset = []\n",
        "classNumber = 0\n",
        "img_size = 100\n",
        "path = \"/content/drive/My Drive/Mask_dataset/Training\"      #path of data used for training"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aTD0oRetjuK",
        "outputId": "45adec76-0982-46cb-e5c4-681fe94bbb27"
      },
      "source": [
        "trainingDataset.clear()\n",
        "\n",
        "###  Read all images category wise  #######\n",
        "for folder in (os.listdir(path)):\n",
        "  print(classNumber)\n",
        "  fp = os.path.join(path,folder)\n",
        "  print(fp)\n",
        "  for eachImage in os.listdir(fp): \n",
        "    imagePath = os.path.join(fp,eachImage)\n",
        "    img = (cv2.imread(imagePath,cv2.IMREAD_GRAYSCALE))/255\n",
        "    resized=cv2.resize(img,(img_size,img_size))\n",
        "    trainingDataset.append([resized,classNumber])\n",
        "  classNumber = classNumber + 1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "/content/drive/My Drive/Mask_dataset/Training/with_mask\n",
            "1\n",
            "/content/drive/My Drive/Mask_dataset/Training/without_mask\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm63EfeBtnZ_"
      },
      "source": [
        "X = []      # for storing image data/features\n",
        "Y = []      # for storing label of images\n",
        "img_size = 100\n",
        "np.random.shuffle(trainingDataset)      # shuffle dataset to prevent overfitting\n",
        "for features, label in trainingDataset:\n",
        "    X.append(features)\n",
        "    Y.append(label)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RQkyYUptsFF",
        "outputId": "20713cdd-10d6-4820-95fe-49a6790cd81c"
      },
      "source": [
        "X = np.array(X).reshape(-1, img_size, img_size, 1)    # reshape in other form --> numpy array\n",
        "Y_binary = to_categorical(Y)                          #categorical type array\n",
        "print('X',X[0])\n",
        "print(Y_binary)\n",
        "print(\"Type\",type(Y_binary))\n",
        "print(len(Y_binary))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X [[[0.92125237]\n",
            "  [0.91769825]\n",
            "  [0.9144255 ]\n",
            "  ...\n",
            "  [0.42781757]\n",
            "  [0.44720574]\n",
            "  [0.43458569]]\n",
            "\n",
            " [[0.91311765]\n",
            "  [0.91362412]\n",
            "  [0.91605784]\n",
            "  ...\n",
            "  [0.42264413]\n",
            "  [0.4096492 ]\n",
            "  [0.39532804]]\n",
            "\n",
            " [[0.92529412]\n",
            "  [0.92529412]\n",
            "  [0.92395588]\n",
            "  ...\n",
            "  [0.41440197]\n",
            "  [0.40701764]\n",
            "  [0.44739707]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.72283107]\n",
            "  [0.65187207]\n",
            "  [0.57426457]\n",
            "  ...\n",
            "  [0.71477491]\n",
            "  [0.66378631]\n",
            "  [0.66976262]]\n",
            "\n",
            " [[0.67024488]\n",
            "  [0.76777126]\n",
            "  [0.74556279]\n",
            "  ...\n",
            "  [0.74735713]\n",
            "  [0.7514593 ]\n",
            "  [0.75599979]]\n",
            "\n",
            " [[0.66390134]\n",
            "  [0.61528229]\n",
            "  [0.71307751]\n",
            "  ...\n",
            "  [0.68798933]\n",
            "  [0.71356249]\n",
            "  [0.73248011]]]\n",
            "[[0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "Type <class 'numpy.ndarray'>\n",
            "1376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DZBb5XJtz4Q"
      },
      "source": [
        "#  Saving features and labels of Data\n",
        "np.save('X',X)\n",
        "np.save('Y_binary',Y_binary)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfOED44hYh1W"
      },
      "source": [
        "#############################################\n",
        "#  Load saved numpy arrays  ##################\n",
        "X=np.load('X.npy')\n",
        "Y_binary=np.load('Y_binary.npy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chBSPVW1Y_cG"
      },
      "source": [
        "# CNN Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c3E23XSbQUN"
      },
      "source": [
        "############  Sequential Model (CNN Architecture)  ############\n",
        "model = Sequential()\n",
        "\n",
        "# 1st CONV2D & MaxPooling Layer\n",
        "model.add(Conv2D(200, (3, 3), input_shape=(100,100,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#model.add(Dropout(0.3))\n",
        "\n",
        "# 2nd Conv2D & MaxPooling Layer\n",
        "model.add(Conv2D(100, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#model.add(Dropout(0.3))\n",
        "\n",
        "\"\"\"\n",
        "model.add(Conv2D(50, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#model.add(Dropout(0.3))\n",
        "\"\"\"\n",
        "# flatten data for feeding to feed forward NN\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.4))       #Dropout\n",
        "model.add(Dense(50))          # Dense layer of 50 neurons\n",
        "model.add(Activation('relu'))  \n",
        "\n",
        "#final Layer \n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax'))  #softmax activation fn for classification"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHqn5QQRbWcW"
      },
      "source": [
        "# Configuration of Model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'],\n",
        "              )"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP0LBi6xbavx"
      },
      "source": [
        "# split training and test data\n",
        "X,test_data,Y_binary,test_target=train_test_split(X,Y_binary,test_size=0.2)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyEUeGF5be8T",
        "outputId": "daf72568-f6f9-4ee8-d2b4-18bdea33965c"
      },
      "source": [
        "# Train the model\n",
        "model.fit(X, Y_binary,batch_size=32,\n",
        "          epochs=30, validation_split = 0.1)\n",
        " \n",
        "\n",
        "# Saving Model\n",
        "model.save(\"Rehan2_Mask.model\") "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "25/25 [==============================] - 58s 2s/step - loss: 0.7918 - accuracy: 0.5249 - val_loss: 0.6638 - val_accuracy: 0.5795\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 57s 2s/step - loss: 0.6187 - accuracy: 0.6593 - val_loss: 0.5177 - val_accuracy: 0.7386\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 57s 2s/step - loss: 0.4281 - accuracy: 0.8103 - val_loss: 0.5025 - val_accuracy: 0.8068\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 57s 2s/step - loss: 0.3062 - accuracy: 0.9006 - val_loss: 0.3577 - val_accuracy: 0.8864\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 56s 2s/step - loss: 0.1847 - accuracy: 0.9389 - val_loss: 0.3540 - val_accuracy: 0.8864\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 57s 2s/step - loss: 0.1395 - accuracy: 0.9542 - val_loss: 0.4544 - val_accuracy: 0.8750\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 56s 2s/step - loss: 0.1175 - accuracy: 0.9533 - val_loss: 0.3722 - val_accuracy: 0.8864\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 57s 2s/step - loss: 0.0743 - accuracy: 0.9764 - val_loss: 0.4795 - val_accuracy: 0.8409\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 56s 2s/step - loss: 0.1052 - accuracy: 0.9589 - val_loss: 0.4102 - val_accuracy: 0.9091\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 56s 2s/step - loss: 0.0681 - accuracy: 0.9800 - val_loss: 0.4494 - val_accuracy: 0.8864\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 56s 2s/step - loss: 0.0432 - accuracy: 0.9836 - val_loss: 0.4146 - val_accuracy: 0.8977\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 57s 2s/step - loss: 0.0249 - accuracy: 0.9963 - val_loss: 0.4405 - val_accuracy: 0.8977\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 56s 2s/step - loss: 0.0338 - accuracy: 0.9924 - val_loss: 0.6467 - val_accuracy: 0.8523\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 57s 2s/step - loss: 0.0851 - accuracy: 0.9661 - val_loss: 0.5018 - val_accuracy: 0.8750\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 57s 2s/step - loss: 0.0243 - accuracy: 0.9924 - val_loss: 0.5659 - val_accuracy: 0.8864\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 57s 2s/step - loss: 0.0190 - accuracy: 0.9955 - val_loss: 0.5058 - val_accuracy: 0.9091\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 56s 2s/step - loss: 0.0153 - accuracy: 0.9970 - val_loss: 0.5826 - val_accuracy: 0.8864\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 57s 2s/step - loss: 0.0289 - accuracy: 0.9890 - val_loss: 0.5075 - val_accuracy: 0.8864\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 56s 2s/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.4855 - val_accuracy: 0.9091\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 56s 2s/step - loss: 0.0167 - accuracy: 0.9946 - val_loss: 0.5214 - val_accuracy: 0.9091\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 56s 2s/step - loss: 0.0318 - accuracy: 0.9911 - val_loss: 0.5790 - val_accuracy: 0.8864\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 56s 2s/step - loss: 0.0134 - accuracy: 0.9975 - val_loss: 0.5710 - val_accuracy: 0.8864\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 56s 2s/step - loss: 0.0122 - accuracy: 0.9955 - val_loss: 0.7637 - val_accuracy: 0.8750\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 56s 2s/step - loss: 0.0108 - accuracy: 0.9945 - val_loss: 0.6912 - val_accuracy: 0.8864\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 56s 2s/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.7865 - val_accuracy: 0.8864\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 56s 2s/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.6172 - val_accuracy: 0.8864\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 56s 2s/step - loss: 0.0414 - accuracy: 0.9818 - val_loss: 0.5407 - val_accuracy: 0.9091\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 56s 2s/step - loss: 0.0336 - accuracy: 0.9903 - val_loss: 0.5572 - val_accuracy: 0.8864\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 56s 2s/step - loss: 0.0333 - accuracy: 0.9866 - val_loss: 0.5864 - val_accuracy: 0.8977\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 56s 2s/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.5940 - val_accuracy: 0.8977\n",
            "INFO:tensorflow:Assets written to: Rehan2_Mask.model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dneQrnVHbiqJ",
        "outputId": "d67d1393-98c3-4f23-dd59-476e37888856"
      },
      "source": [
        "#Evaluate model on testing data\n",
        "print(model.evaluate(test_data,test_target))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 4s 603ms/step - loss: 0.1526 - accuracy: 0.9727\n",
            "[0.1526496559381485, 0.9727272987365723]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqhKmLYwZeQN"
      },
      "source": [
        "# Make Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu-dZh8wbmQn",
        "outputId": "4168455d-5f47-43ca-d15e-613ccf0da51e"
      },
      "source": [
        "\n",
        "def prepare(filepath):\n",
        "    img_size = 100 \n",
        "    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)/255  \n",
        "    img_resize = cv2.resize(img, (img_size, img_size))\n",
        "    #cv2.imshow('image',img)\n",
        "    #print(img_resize.reshape(-1, img_size, img_size, 1))  \n",
        "    return img_resize.reshape(-1, img_size, img_size, 1)\n",
        "\n",
        "image_path=\"1802008_10.jpg\"\n",
        "#image_read=cv2.imread(image_path)\n",
        "prediction = model.predict(prepare(image_path))\n",
        "\n",
        "print((prediction))\n",
        "\n",
        "CATEGORIES = [\"With Mask\", \"Without Mask\"]\n",
        "pred_class = CATEGORIES[np.argmax(prediction)]\n",
        "print(pred_class)\n",
        "#cv2.imshow(pred_class,image_read)\n",
        "\n",
        "\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8.7405424e-05 9.9991262e-01]]\n",
            "Without Mask\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfIXCrvfbtY0",
        "outputId": "34a72c27-ddbe-4de9-a922-2869cdcd8f31"
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/1f/632d04bec71d4736a4e0e512cf41236b3416ac00d0a532f6511a829d18c9/tensorflowjs-3.3.0-py3-none-any.whl (63kB)\n",
            "\r\u001b[K     |█████▏                          | 10kB 10.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 30kB 10.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 40kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 51kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 61kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (2.10.0)\n",
            "Requirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (1.15.0)\n",
            "Collecting tensorflow-hub<0.10,>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/83/a7df82744a794107641dad1decaad017d82e25f0e1f761ac9204829eef96/tensorflow_hub-0.9.0-py2.py3-none-any.whl (103kB)\n",
            "\r\u001b[K     |███▏                            | 10kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 20kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 30kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 40kB 14.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 51kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 61kB 11.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 71kB 10.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 81kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 92kB 10.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 102kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 10.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (2.4.1)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py<3,>=2.8.0->tensorflowjs) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub<0.10,>=0.7.0->tensorflowjs) (3.12.4)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.3.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.4.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.4.1)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.36.2)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.32.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.7.4.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow-hub<0.10,>=0.7.0->tensorflowjs) (54.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.28.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (4.7.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
            "Installing collected packages: tensorflow-hub, tensorflowjs\n",
            "  Found existing installation: tensorflow-hub 0.11.0\n",
            "    Uninstalling tensorflow-hub-0.11.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.11.0\n",
            "Successfully installed tensorflow-hub-0.9.0 tensorflowjs-3.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbD4sigSbuQr"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflowjs as tfjs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qxul9BssZneg"
      },
      "source": [
        "# Storing Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TZIEgITbxrM",
        "outputId": "9d851edc-55e9-4be5-8b19-2b122bf2875b"
      },
      "source": [
        "tfjs.converters.save_keras_model(model, 'models')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflowjs/converters/keras_h5_conversion.py:123: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  return h5py.File(h5file)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}